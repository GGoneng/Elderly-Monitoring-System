{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------------\n",
    "# 파일명       : LSTM_model.ipynb\n",
    "# 설명         : LSTM 모델 학습\n",
    "# 작성자       : 이민하\n",
    "# 작성일       : 2024-11-13\n",
    "# \n",
    "# 사용 모듈    :\n",
    "# - pandas                           # 데이터프레임 기반 데이터 처리\n",
    "# - pickle                           # 객체 저장 및 로딩 (직렬화)\n",
    "# - os                               # 파일 및 경로 관리\n",
    "# - torch, torch.nn, F               # PyTorch 모델 구축 및 연산\n",
    "# - torch.utils.data                 # 데이터셋 및 데이터로더 처리\n",
    "# - sklearn.model_selection          # 학습/검증용 데이터 분할\n",
    "# - sklearn.preprocessing            # 데이터 정규화 및 스케일링\n",
    "# - torch.optim, lr_scheduler        # 최적화 및 학습률 조정\n",
    "# - torchmetrics.regression          # 회귀 모델 평가 지표 계산\n",
    "# -----------------------------------------------------------------------------------\n",
    "# >> 주요 기능\n",
    "# - 데이터 및 모델 불러오기\n",
    "# - 모델 학습\n",
    "#\n",
    "# >> 업데이트 내역\n",
    "# [2024-11-13] 이상 패턴 제거 전 데이터 학습\n",
    "# [2024-11-14] 데이터 변경 (56 dimensions)\n",
    "# [2024-11-28] 데이터 변경 (이상 패턴 제거 후 29 dimensions)\n",
    "# -----------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 기반 데이터 처리\n",
    "import pandas as pd\n",
    "\n",
    "# 객체 저장 및 로딩 (직렬화)\n",
    "import pickle\n",
    "\n",
    "# 경로 관리\n",
    "import os\n",
    "\n",
    "# PyTorch 모델 구축 및 연산\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 데이터셋 및 데이터로더 처리\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 학습/검증용 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 정규화 및 스케일링\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "\n",
    "# 최적화 및 학습률 조정\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# 회귀 모델 평가 지표 계산\n",
    "from torchmetrics.regression import R2Score, MeanAbsoluteError, MeanAbsolutePercentageError, MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "DATA_PATH = '../Data/'\n",
    "\n",
    "# 29 dimensions를 가진 데이터 불러오기 (이상 패턴 제거)\n",
    "electric_df = pd.read_csv(DATA_PATH + 'electric_df_clear_29_days.csv')\n",
    "water_df = pd.read_csv(DATA_PATH + 'water_df_clear_29_days.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>120</td>\n",
       "      <td>210</td>\n",
       "      <td>410</td>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>180</td>\n",
       "      <td>260</td>\n",
       "      <td>35</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>46</td>\n",
       "      <td>139</td>\n",
       "      <td>204</td>\n",
       "      <td>198</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>210</td>\n",
       "      <td>410</td>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>180</td>\n",
       "      <td>260</td>\n",
       "      <td>35</td>\n",
       "      <td>145</td>\n",
       "      <td>203</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>139</td>\n",
       "      <td>204</td>\n",
       "      <td>198</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>51</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210</td>\n",
       "      <td>410</td>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>180</td>\n",
       "      <td>260</td>\n",
       "      <td>35</td>\n",
       "      <td>145</td>\n",
       "      <td>203</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>139</td>\n",
       "      <td>204</td>\n",
       "      <td>198</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>51</td>\n",
       "      <td>169</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>410</td>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>180</td>\n",
       "      <td>260</td>\n",
       "      <td>35</td>\n",
       "      <td>145</td>\n",
       "      <td>203</td>\n",
       "      <td>216</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>204</td>\n",
       "      <td>198</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>51</td>\n",
       "      <td>169</td>\n",
       "      <td>204</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>180</td>\n",
       "      <td>260</td>\n",
       "      <td>35</td>\n",
       "      <td>145</td>\n",
       "      <td>203</td>\n",
       "      <td>216</td>\n",
       "      <td>43</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>51</td>\n",
       "      <td>169</td>\n",
       "      <td>204</td>\n",
       "      <td>169</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285993</th>\n",
       "      <td>157</td>\n",
       "      <td>230</td>\n",
       "      <td>169</td>\n",
       "      <td>47</td>\n",
       "      <td>122</td>\n",
       "      <td>218</td>\n",
       "      <td>350</td>\n",
       "      <td>110</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>218</td>\n",
       "      <td>290</td>\n",
       "      <td>105</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>263</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285994</th>\n",
       "      <td>230</td>\n",
       "      <td>169</td>\n",
       "      <td>47</td>\n",
       "      <td>122</td>\n",
       "      <td>218</td>\n",
       "      <td>350</td>\n",
       "      <td>110</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>230</td>\n",
       "      <td>...</td>\n",
       "      <td>218</td>\n",
       "      <td>290</td>\n",
       "      <td>105</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>263</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285995</th>\n",
       "      <td>169</td>\n",
       "      <td>47</td>\n",
       "      <td>122</td>\n",
       "      <td>218</td>\n",
       "      <td>350</td>\n",
       "      <td>110</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>230</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>290</td>\n",
       "      <td>105</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>263</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>290</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285996</th>\n",
       "      <td>47</td>\n",
       "      <td>122</td>\n",
       "      <td>218</td>\n",
       "      <td>350</td>\n",
       "      <td>110</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>230</td>\n",
       "      <td>98</td>\n",
       "      <td>143</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>263</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>290</td>\n",
       "      <td>300</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285997</th>\n",
       "      <td>122</td>\n",
       "      <td>218</td>\n",
       "      <td>350</td>\n",
       "      <td>110</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>230</td>\n",
       "      <td>98</td>\n",
       "      <td>143</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>263</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>290</td>\n",
       "      <td>300</td>\n",
       "      <td>280</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285998 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9  ...   19   20   21  \\\n",
       "0        30  120  210  410   32  184  180  260   35  145  ...   95   46  139   \n",
       "1       120  210  410   32  184  180  260   35  145  203  ...   46  139  204   \n",
       "2       210  410   32  184  180  260   35  145  203  216  ...  139  204  198   \n",
       "3       410   32  184  180  260   35  145  203  216   43  ...  204  198   53   \n",
       "4        32  184  180  260   35  145  203  216   43  136  ...  198   53  162   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "285993  157  230  169   47  122  218  350  110  183  190  ...   58  218  290   \n",
       "285994  230  169   47  122  218  350  110  183  190  230  ...  218  290  105   \n",
       "285995  169   47  122  218  350  110  183  190  230   98  ...  290  105   10   \n",
       "285996   47  122  218  350  110  183  190  230   98  143  ...  105   10   68   \n",
       "285997  122  218  350  110  183  190  230   98  143  253  ...   10   68   38   \n",
       "\n",
       "         22   23   24   25   26   27   28  \n",
       "0       204  198   53  162  210  150   51  \n",
       "1       198   53  162  210  150   51  169  \n",
       "2        53  162  210  150   51  169  204  \n",
       "3       162  210  150   51  169  204  169  \n",
       "4       210  150   51  169  204  169   38  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  \n",
       "285993  105   10   68   38  263   78  158  \n",
       "285994   10   68   38  263   78  158  290  \n",
       "285995   68   38  263   78  158  290  300  \n",
       "285996   38  263   78  158  290  300  280  \n",
       "285997  263   78  158  290  300  280  160  \n",
       "\n",
       "[285998 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Test 데이터 나누기 (Test Size = 0.2)\n",
    "\n",
    "# electric_features = electric_df[electric_df.columns[:-1]]\n",
    "# electric_target = electric_df[electric_df.columns[-1:]]\n",
    "\n",
    "# electric_X_train, electric_X_test, electric_y_train, electric_y_test = train_test_split(electric_features,\n",
    "#                                                     electric_target,\n",
    "#                                                     random_state = 42,\n",
    "                                                    # test_size = 0.2)\n",
    "\n",
    "water_features = water_df[water_df.columns[:-1]]\n",
    "water_target = water_df[water_df.columns[-1:]]\n",
    "\n",
    "water_X_train, water_X_test, water_y_train, water_y_test = train_test_split(water_features,\n",
    "                                                                            water_target,\n",
    "                                                                            random_state = 42,\n",
    "                                                                            test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 연산을 위한 데이터셋\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        self.featureDF = featureDF\n",
    "        self.targetDF = targetDF\n",
    "        self.n_rows = self.featureDF.shape[0]\n",
    "        self.n_cols = self.featureDF.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        featureTS = torch.FloatTensor(self.featureDF.iloc[index].values)\n",
    "        targetTS = torch.FloatTensor(self.targetDF.iloc[index].values)\n",
    "\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, input_size, n_layers, dropout,\n",
    "                 bidirectional):\n",
    "        super().__init__()\n",
    "\n",
    "        # LSTM 모델\n",
    "        self.model = nn.LSTM(\n",
    "            input_size = input_size,\n",
    "            hidden_size = hidden_dim,\n",
    "            num_layers = n_layers,\n",
    "            dropout = dropout,\n",
    "            bidirectional = bidirectional,\n",
    "            batch_first = True\n",
    "        )\n",
    "\n",
    "        # 출력층 \n",
    "        # 양방향 LSTM (시퀀스 데이터에서 더 많은 정보 추출 가능)\n",
    "        if bidirectional:\n",
    "            self.linear = nn.Linear(hidden_dim * 2, 1)\n",
    "        \n",
    "        else:\n",
    "            self.linear = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # 성능에 따라 추가\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output, _ = self.model(inputs)\n",
    "        logits = self.linear(output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전기 데이터는 MinMaxScaler를 통해 스케일링\n",
    "# electric_mmscaler = MinMaxScaler().fit(electric_X_train)\n",
    "\n",
    "# 수도 데이터는 RobustScaler를 통해 스케일링\n",
    "water_rbscaler = RobustScaler().fit(water_X_train)\n",
    "\n",
    "# pickle 모듈을 통해 전기 스케일러 저장\n",
    "# with open('electric_min_max_scaler.pkl', 'wb') as f:\n",
    "#     pickle.dump(electric_mmscaler, f)\n",
    "\n",
    "# pickle 모듈을 통해 수도 스케일러 저장\n",
    "with open('water_robust_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(water_rbscaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전기, 수도 데이터를 스케일링된 데이터로 변경\n",
    "# electric_X_train_scaled = electric_mmscaler.transform(electric_X_train)\n",
    "# electric_X_test_scaled = electric_mmscaler.transform(electric_X_test)\n",
    "\n",
    "water_X_train_scaled = water_rbscaler.transform(water_X_train)\n",
    "water_X_test_scaled = water_rbscaler.transform(water_X_test)\n",
    "\n",
    "# 스케일링된 데이터로 데이터프레임 재구성\n",
    "# electric_X_train = pd.DataFrame(electric_X_train_scaled, columns = electric_X_train.columns)\n",
    "# electric_X_test = pd.DataFrame(electric_X_test_scaled, columns = electric_X_test.columns)\n",
    "\n",
    "water_X_train = pd.DataFrame(water_X_train_scaled, columns = water_X_train.columns)\n",
    "water_X_test = pd.DataFrame(water_X_test_scaled, columns = water_X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 파라미터 설정\n",
    "EPOCH = 1000\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋, 데이터로더 변환\n",
    "# electric_trainDS = CustomDataset(electric_X_train, electric_y_train)\n",
    "water_trainDS = CustomDataset(water_X_train, water_y_train)\n",
    "\n",
    "# electric_trainDL = DataLoader(electric_trainDS, batch_size = BATCH_SIZE)\n",
    "water_trainDL = DataLoader(water_trainDS, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 파라미터 설정\n",
    "input_size = 28\n",
    "hidden_dim = 32\n",
    "n_layers = 2\n",
    "dropout = 0.5\n",
    "\n",
    "# 모델 생성\n",
    "lstm_model = LSTMModel(input_size = input_size, hidden_dim = hidden_dim,\n",
    "                       n_layers = n_layers, dropout = 0.8, bidirectional = True).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 손실 함수 생성\n",
    "MAEloss = MeanAbsoluteError()\n",
    "MAPEloss = MeanAbsolutePercentageError()\n",
    "MSEloss = MeanSquaredError()\n",
    "R2score = R2Score()\n",
    "\n",
    "# 옵티마이저 생성\n",
    "optimizer = optim.RMSprop(lstm_model.parameters(), lr = LR)\n",
    "\n",
    "# Learning Rate Scheduler 생성\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', patience = 10, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 Test 함수\n",
    "def testing(featureDF, targetDF, model):\n",
    "    # Pytorch 학습을 위해 데이터프레임 -> 텐서 전환\n",
    "    featureTS = torch.FloatTensor(featureDF.values).to(DEVICE)\n",
    "    targetTS = torch.FloatTensor(targetDF.values).to(DEVICE)\n",
    "\n",
    "    # Dropout, BatchNorm 등 가중치 규제 비활성화    \n",
    "    model.eval()\n",
    "    \n",
    "    # 평가를 위해 역전파 계산 X\n",
    "    with torch.no_grad():\n",
    "        pre_val = model(featureTS)\n",
    "        mae_loss_val = MAEloss(pre_val, targetTS)\n",
    "        mape_loss_val = MAPEloss(pre_val, targetTS)\n",
    "        mse_loss_val = MSEloss(pre_val, targetTS)\n",
    "        score_val = R2score(pre_val, targetTS)\n",
    "    \n",
    "    return mae_loss_val, mape_loss_val, mse_loss_val, score_val, pre_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 Train 함수\n",
    "def training(testDF, testtargetDF, model, trainDL, test_value):\n",
    "    \n",
    "    # 가중치 파일 저장 위치 정의\n",
    "    SAVE_PATH = './saved_models/'\n",
    "    os.makedirs(SAVE_PATH, exist_ok = True)\n",
    "    \n",
    "    # Early Stopping을 위한 변수\n",
    "    BREAK_CNT_LOSS = 0\n",
    "    BREAK_CNT_SCORE = 0\n",
    "    LIMIT_VALUE = 10\n",
    "\n",
    "    # Loss가 더 낮은 가중치 파일을 저장하기 위하여 Loss 로그를 담을 리스트\n",
    "    MAE_LOSS_HISTORY, MAPE_LOSS_HISTORY, MSE_LOSS_HISTORY, SCORE_HISTORY = [[], []], [[], []], [[], []], [[], []]\n",
    "\n",
    "    for epoch in range(1, EPOCH + 1):\n",
    "        SAVE_MODEL = os.path.join(SAVE_PATH, f'model_{epoch}.pth')\n",
    "        SAVE_WEIGHT = os.path.join(SAVE_PATH, f'model_weights_{epoch}.pth')\n",
    "\n",
    "        mae_loss_total, mape_loss_total, mse_loss_total, score_total = 0, 0, 0, 0\n",
    "\n",
    "        # Train DataLoader에 저장된 feature, target 텐서로 학습 진행\n",
    "        for featureTS, targetTS in trainDL:\n",
    "            # 결과 추론\n",
    "            pre_y = model(featureTS)\n",
    "            \n",
    "            # 추론값으로 Loss값 계산\n",
    "            mae_loss = MAEloss(pre_y, targetTS)\n",
    "            mape_loss = MAPEloss(pre_y, targetTS)\n",
    "            mse_loss = MSEloss(pre_y, targetTS)\n",
    "\n",
    "            mae_loss_total += mae_loss.item()\n",
    "            mape_loss_total += mape_loss.item()\n",
    "            mse_loss_total += mse_loss.item()\n",
    "\n",
    "            score = R2score(pre_y, targetTS)\n",
    "            score_total += score.item()\n",
    "\n",
    "            # mae, mape, mse loss 전부 더한 값으로 기울기 \n",
    "            total_loss = mae_loss + mape_loss + mse_loss\n",
    "\n",
    "            # 이전 gradient 초기화\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 역전파로 gradient 계산\n",
    "            total_loss.backward()\n",
    "\n",
    "            # 계산된 gradient로 가중치 업데이트\n",
    "            optimizer.step()\n",
    "\n",
    "        # test loss, score, 예측값도 계산\n",
    "        test_mae_loss, test_mape_loss, test_mse_loss, test_score, pre_val = testing(testDF, testtargetDF, model)\n",
    "\n",
    "        MAE_LOSS_HISTORY[1].append(test_mae_loss)\n",
    "        MAPE_LOSS_HISTORY[1].append(test_mape_loss)\n",
    "        MSE_LOSS_HISTORY[1].append(test_mse_loss)\n",
    "        SCORE_HISTORY[1].append(test_score)\n",
    "\n",
    "        MAE_LOSS_HISTORY[0].append(mae_loss_total / len(trainDL))\n",
    "        MAPE_LOSS_HISTORY[0].append(mape_loss_total / len(trainDL))\n",
    "        MSE_LOSS_HISTORY[0].append(mse_loss_total / len(trainDL))\n",
    "        SCORE_HISTORY[0].append(score_total / len(trainDL))\n",
    "\n",
    "        print(f'pre_val : {pre_val.squeeze().tolist()[:10]}\\ny_val : {test_value.values.squeeze()[:10]}\\n')\n",
    "        print(f'[{epoch} / {EPOCH}]\\n- TRAIN MAE LOSS : {MAE_LOSS_HISTORY[0][-1]}')\n",
    "        print(f'- TRAIN MAPE LOSS : {MAPE_LOSS_HISTORY[0][-1]}')\n",
    "        print(f'- TRAIN MSE LOSS : {MSE_LOSS_HISTORY[0][-1]}')\n",
    "        print(f'- TRAIN R2 SCORE : {SCORE_HISTORY[0][-1]}')\n",
    "\n",
    "        print(f'\\n- TEST MAE LOSS : {MAE_LOSS_HISTORY[1][-1]}')\n",
    "        print(f'- TEST MAPE LOSS : {MAPE_LOSS_HISTORY[1][-1]}')\n",
    "        print(f'- TEST MSE LOSS : {MSE_LOSS_HISTORY[1][-1]}')\n",
    "        print(f'- TEST R2 SCORE : {SCORE_HISTORY[1][-1]}')\n",
    "\n",
    "        # test loss 결과로 스케줄러 업데이트\n",
    "        scheduler.step(test_mae_loss)\n",
    "\n",
    "        # Early Stopping 구현\n",
    "        if len(MAE_LOSS_HISTORY[1]) >= 2:\n",
    "            if MAE_LOSS_HISTORY[1][-1] >= MAE_LOSS_HISTORY[1][-2]: BREAK_CNT_LOSS += 1\n",
    "        \n",
    "        if len(MAE_LOSS_HISTORY[1]) == 1:\n",
    "            torch.save(model.state_dict(), SAVE_WEIGHT)\n",
    "            torch.save(model, SAVE_MODEL)\n",
    "\n",
    "        else:\n",
    "            if MAE_LOSS_HISTORY[1][-1] < min(MAE_LOSS_HISTORY[1][:-1]):\n",
    "                torch.save(model.state_dict(), SAVE_WEIGHT)\n",
    "                torch.save(model, SAVE_MODEL)\n",
    "\n",
    "        if BREAK_CNT_LOSS > LIMIT_VALUE:\n",
    "            print(f\"성능 및 손실 개선이 없어서 {epoch} EPOCH에 학습 중단\")\n",
    "            break\n",
    "\n",
    "    return MAE_LOSS_HISTORY, MAPE_LOSS_HISTORY, MSE_LOSS_HISTORY, SCORE_HISTORY\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mae_loss, mape_loss, mse_loss, r2 \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m(water_X_test, water_y_test, lstm_model, water_trainDL, water_y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training' is not defined"
     ]
    }
   ],
   "source": [
    "# 모델 학습 시작\n",
    "mae_loss, mape_loss, mse_loss, r2 = training(water_X_test, water_y_test, lstm_model, water_trainDL, water_y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
